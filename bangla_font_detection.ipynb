{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bangla font detection.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOBZgc98go+yZ3R3LiFh0M0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majedrifat/models/blob/master/bangla_font_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLH6juDLo-nk",
        "colab_type": "code",
        "outputId": "ecb8b741-7abd-474d-b577-620af2e3c929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pylab as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import ImageFilter\n",
        "import cv2\n",
        "import itertools\n",
        "import random\n",
        "import keras\n",
        "import imutils\n",
        "from imutils import paths\n",
        "import os\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras import callbacks\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose\n",
        "from keras import backend as K\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zf0f667xOTY",
        "colab_type": "code",
        "outputId": "f390de2b-c5d5-4c79-e3c8-c8025ae62319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip font_patch1.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  font_patch1.zip\n",
            "   creating: font_patch/\n",
            "   creating: font_patch/adorsolipi/\n",
            "  inflating: font_patch/adorsolipi/1 (11).png  \n",
            "  inflating: font_patch/adorsolipi/1 (12).png  \n",
            "  inflating: font_patch/adorsolipi/1 (15).png  \n",
            "  inflating: font_patch/adorsolipi/1 (16).png  \n",
            "  inflating: font_patch/adorsolipi/1 (3).png  \n",
            "  inflating: font_patch/adorsolipi/1 (4).png  \n",
            "  inflating: font_patch/adorsolipi/1 (5).png  \n",
            "  inflating: font_patch/adorsolipi/1 (6).png  \n",
            " extracting: font_patch/adorsolipi/3 (56).png  \n",
            "  inflating: font_patch/adorsolipi/3 (57).png  \n",
            "  inflating: font_patch/adorsolipi/3 (66).png  \n",
            "  inflating: font_patch/adorsolipi/3 (67).png  \n",
            " extracting: font_patch/adorsolipi/3 (78).png  \n",
            " extracting: font_patch/adorsolipi/3 (79).png  \n",
            "   creating: font_patch/kalpurush/\n",
            " extracting: font_patch/kalpurush/1 (143).png  \n",
            "  inflating: font_patch/kalpurush/1 (213).png  \n",
            "  inflating: font_patch/kalpurush/1 (214).png  \n",
            " extracting: font_patch/kalpurush/1 (4).png  \n",
            "  inflating: font_patch/kalpurush/1 (48).png  \n",
            " extracting: font_patch/kalpurush/1 (57).png  \n",
            "  inflating: font_patch/kalpurush/1 (6).png  \n",
            "  inflating: font_patch/kalpurush/1 (66).png  \n",
            "  inflating: font_patch/kalpurush/2 (1).png  \n",
            "  inflating: font_patch/kalpurush/2 (13).png  \n",
            "  inflating: font_patch/kalpurush/2 (20).png  \n",
            "  inflating: font_patch/kalpurush/2 (23).png  \n",
            " extracting: font_patch/kalpurush/2 (25).png  \n",
            "  inflating: font_patch/kalpurush/2 (26).png  \n",
            "  inflating: font_patch/kalpurush/2 (29).png  \n",
            "  inflating: font_patch/kalpurush/2 (32).png  \n",
            "  inflating: font_patch/kalpurush/2 (37).png  \n",
            "  inflating: font_patch/kalpurush/2 (42).png  \n",
            "  inflating: font_patch/kalpurush/2 (43).png  \n",
            "  inflating: font_patch/kalpurush/2 (7).png  \n",
            "   creating: font_patch/lohit/\n",
            " extracting: font_patch/lohit/1 (114).png  \n",
            "  inflating: font_patch/lohit/1 (147).png  \n",
            "  inflating: font_patch/lohit/1 (156).png  \n",
            "  inflating: font_patch/lohit/1 (159).png  \n",
            "  inflating: font_patch/lohit/1 (167).png  \n",
            "  inflating: font_patch/lohit/1 (172).png  \n",
            "  inflating: font_patch/lohit/1 (23).png  \n",
            "  inflating: font_patch/lohit/1 (3).png  \n",
            "  inflating: font_patch/lohit/1 (35).png  \n",
            "  inflating: font_patch/lohit/1 (46).png  \n",
            " extracting: font_patch/lohit/1 (48).png  \n",
            "  inflating: font_patch/lohit/1 (5).png  \n",
            "  inflating: font_patch/lohit/1 (53).png  \n",
            "  inflating: font_patch/lohit/1 (54).png  \n",
            "  inflating: font_patch/lohit/1 (84).png  \n",
            "  inflating: font_patch/lohit/1 (88).png  \n",
            "  inflating: font_patch/lohit/1 (99).png  \n",
            "   creating: font_patch/nikosh/\n",
            "  inflating: font_patch/nikosh/1 (1).png  \n",
            "  inflating: font_patch/nikosh/1 (147).png  \n",
            "  inflating: font_patch/nikosh/1 (149).png  \n",
            "  inflating: font_patch/nikosh/1 (150).png  \n",
            "  inflating: font_patch/nikosh/1 (153).png  \n",
            "  inflating: font_patch/nikosh/1 (154).png  \n",
            "  inflating: font_patch/nikosh/1 (166).png  \n",
            "  inflating: font_patch/nikosh/1 (221).png  \n",
            "  inflating: font_patch/nikosh/1 (226).png  \n",
            "  inflating: font_patch/nikosh/1 (234).png  \n",
            "  inflating: font_patch/nikosh/2 (117).png  \n",
            "  inflating: font_patch/nikosh/2 (12).png  \n",
            "  inflating: font_patch/nikosh/2 (133).png  \n",
            "  inflating: font_patch/nikosh/2 (134).png  \n",
            " extracting: font_patch/nikosh/2 (19).png  \n",
            "  inflating: font_patch/nikosh/2 (22).png  \n",
            "  inflating: font_patch/nikosh/2 (23).png  \n",
            "  inflating: font_patch/nikosh/2 (34).png  \n",
            "  inflating: font_patch/nikosh/2 (37).png  \n",
            "   creating: font_patch/rupali/\n",
            "  inflating: font_patch/rupali/1 (102).png  \n",
            "  inflating: font_patch/rupali/1 (105).png  \n",
            "  inflating: font_patch/rupali/1 (16).png  \n",
            "  inflating: font_patch/rupali/1 (21).png  \n",
            "  inflating: font_patch/rupali/1 (22).png  \n",
            "  inflating: font_patch/rupali/1 (24).png  \n",
            "  inflating: font_patch/rupali/1 (275).png  \n",
            "  inflating: font_patch/rupali/1 (29).png  \n",
            "  inflating: font_patch/rupali/1 (3).png  \n",
            "  inflating: font_patch/rupali/1 (36).png  \n",
            "  inflating: font_patch/rupali/1 (6).png  \n",
            "  inflating: font_patch/rupali/1 (83).png  \n",
            "  inflating: font_patch/rupali/1 (89).png  \n",
            "  inflating: font_patch/rupali/1 (9).png  \n",
            "  inflating: font_patch/rupali/2 (113).png  \n",
            " extracting: font_patch/rupali/2 (133).png  \n",
            " extracting: font_patch/rupali/2 (134).png  \n",
            "  inflating: font_patch/rupali/2 (144).png  \n",
            "   creating: font_patch/solaimanlipi/\n",
            "  inflating: font_patch/solaimanlipi/1 (10).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (12).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (15).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (282).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (293).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (3).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (30).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (33).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (6).png  \n",
            "  inflating: font_patch/solaimanlipi/1 (66).png  \n",
            "  inflating: font_patch/solaimanlipi/2 (13).png  \n",
            " extracting: font_patch/solaimanlipi/2 (23).png  \n",
            "  inflating: font_patch/solaimanlipi/2 (24).png  \n",
            " extracting: font_patch/solaimanlipi/2 (54).png  \n",
            "  inflating: font_patch/solaimanlipi/2 (95).png  \n",
            "  inflating: font_patch/solaimanlipi/2 (98).png  \n",
            "   creating: font_patch/sonar_bangla/\n",
            "  inflating: font_patch/sonar_bangla/1 (106).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (108).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (148).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (155).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (167).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (172).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (18).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (268).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (269).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (270).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (274).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (4).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (5).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (6).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (9).png  \n",
            "  inflating: font_patch/sonar_bangla/1 (93).png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWMkWlW8pDCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pil_image(img_path):\n",
        "    pil_im =PIL.Image.open(img_path).convert('L')\n",
        "    pil_im=pil_im.resize((105,105))\n",
        "    #imshow(np.asarray(pil_im))\n",
        "    return pil_im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_6Et2kpHU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noise_image(pil_im):\n",
        "    # Adding Noise to image\n",
        "    img_array = np.asarray(pil_im)\n",
        "    mean = 0.0   # some constant\n",
        "    std = 5   # some constant (standard deviation)\n",
        "    noisy_img = img_array + np.random.normal(mean, std, img_array.shape)\n",
        "    noisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
        "    noise_img = PIL.Image.fromarray(np.uint8(noisy_img_clipped)) # output\n",
        "    #imshow((noisy_img_clipped ).astype(np.uint8))\n",
        "    noise_img=noise_img.resize((105,105))\n",
        "    return noise_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsQ9sHBpLCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def blur_image(pil_im):\n",
        "    #Adding Blur to image \n",
        "    blur_img = pil_im.filter(ImageFilter.GaussianBlur(radius=3)) # ouput\n",
        "    #imshow(blur_img)\n",
        "    blur_img=blur_img.resize((105,105))\n",
        "    return blur_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ft62RRxpOdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def affine_rotation(img):\n",
        "    \n",
        "    #img=cv2.imread(img_path,0)\n",
        "    rows, columns = img.shape\n",
        "\n",
        "    point1 = np.float32([[10, 10], [30, 10], [10, 30]])\n",
        "    point2 = np.float32([[20, 15], [40, 10], [20, 40]])\n",
        "\n",
        "    A = cv2.getAffineTransform(point1, point2)\n",
        "\n",
        "    output = cv2.warpAffine(img, A, (columns, rows))\n",
        "    affine_img = PIL.Image.fromarray(np.uint8(output)) # affine rotated output\n",
        "    #imshow(output)\n",
        "    affine_img=affine_img.resize((105,105))\n",
        "    return affine_img\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM6QlKTDpQ4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_fill(image):\n",
        "    #image=cv2.imread(img_path,0)\n",
        "    laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
        "    laplacian = cv2.resize(laplacian, (105, 105))\n",
        "    return laplacian"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9jyOLXLpS1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"/content/font_patch/\"\n",
        "data=[]\n",
        "labels=[]\n",
        "imagePaths = sorted(list(paths.list_images(data_path)))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE5QUjgWpUz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def conv_label(label):\n",
        "    if label == 'adorsolipi':\n",
        "        return 0\n",
        "    elif label == 'kalpurush':\n",
        "        return 1\n",
        "    elif label == 'lohit':\n",
        "        return 2\n",
        "    elif label == 'nikosh':\n",
        "        return 3\n",
        "    elif label == 'rupali':\n",
        "        return 4\n",
        "    elif label == 'solaimanlipi':\n",
        "        return 5\n",
        "    elif label == 'sonar_bangla':\n",
        "        return 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjy_5dqwpWj9",
        "colab_type": "code",
        "outputId": "e8a80323-6d1a-4e8e-a268-94351e8dda94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "augument=[\"blur\",\"noise\",\"affine\",\"gradient\"]\n",
        "a=itertools.combinations(augument, 4)\n",
        "\n",
        "for i in list(a): \n",
        "    print(list(i))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['blur', 'noise', 'affine', 'gradient']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMR7BbNTpX8V",
        "colab_type": "code",
        "outputId": "c28760e2-911f-4a39-c10e-db894038a073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "counter=0\n",
        "for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    label = conv_label(label)\n",
        "    pil_img = pil_image(imagePath)\n",
        "    #imshow(pil_img)\n",
        "    \n",
        "    # Adding original image\n",
        "    org_img = img_to_array(pil_img)\n",
        "    #print(org_img.shape)\n",
        "    data.append(org_img)\n",
        "    labels.append(label)\n",
        "    \n",
        "    augument=[\"noise\",\"blur\",\"affine\",\"gradient\"]\n",
        "    for l in range(0,len(augument)):\n",
        "    \n",
        "        a=itertools.combinations(augument, l+1)\n",
        "\n",
        "        for i in list(a): \n",
        "            combinations=list(i)\n",
        "            print(len(combinations))\n",
        "            temp_img = pil_img\n",
        "            for j in combinations:\n",
        "            \n",
        "                if j == 'noise':\n",
        "                    # Adding Noise image\n",
        "                    temp_img = noise_image(temp_img)\n",
        "                    \n",
        "                elif j == 'blur':\n",
        "                    # Adding Blur image\n",
        "                    temp_img = blur_image(temp_img)\n",
        "                    #imshow(blur_img)\n",
        "                    \n",
        "    \n",
        "                elif j == 'affine':\n",
        "                    open_cv_affine = np.array(pil_img)\n",
        "                    # Adding affine rotation image\n",
        "                    temp_img = affine_rotation(open_cv_affine)\n",
        "\n",
        "                elif j == 'gradient':\n",
        "                    open_cv_gradient = np.array(pil_img)\n",
        "                    # Adding gradient image\n",
        "                    temp_img = gradient_fill(open_cv_gradient)\n",
        "  \n",
        "            temp_img = img_to_array(temp_img)\n",
        "            data.append(temp_img)\n",
        "            labels.append(label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVrb1fa8pZWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0464d28d-32f8-4bde-95e9-78ef8d059d70"
      },
      "source": [
        "data = np.asarray(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "print(\"Success\")\n",
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\tlabels, test_size=0.25, random_state=42)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmbXcRUcpcMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "trainY = np.array(trainY)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "vec = label_encoder.fit_transform(trainY)\n",
        "trainY = to_categorical(vec, num_classes=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmEfej7qpfwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the labels from integers to vectors\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "testY = np.array(testY)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "vec2 = label_encoder.fit_transform(testY)\n",
        "testY = to_categorical(vec2, num_classes=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O907oPo4piKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl_jGJCrpleK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.common.image_dim_ordering()\n",
        "K.common.set_image_dim_ordering('tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezzAyy0Tpnc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def create_model():\n",
        "        model=Sequential()\n",
        "        # Cu Layers \n",
        "        model.add(Conv2D(64, kernel_size=(48, 48), activation='relu', input_shape=(105,105,1)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(128, kernel_size=(24, 24), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2DTranspose(128, (24,24), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
        "        model.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2DTranspose(64, (12,12), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
        "        model.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "        #Cs Layers\n",
        "        model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
        "\n",
        "        model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
        "\n",
        "        model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
        "\n",
        "        model.add(Flatten())\n",
        "\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(4096,activation='relu'))\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Dense(2383,activation='relu'))\n",
        "\n",
        "        model.add(Dense(7, activation='softmax'))\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGUilYnYpq2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 50\n",
        "model= create_model()\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YodBYeY6pt3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
        "\n",
        "filepath=\"top_model.h5\"\n",
        "\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "callbacks_list = [early_stopping,checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSotlDwRpwif",
        "colab_type": "code",
        "outputId": "065d6c4a-2c0a-48fb-ccec-77ee630d7a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY,shuffle=True,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(testX, testY),callbacks=callbacks_list)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1440 samples, validate on 480 samples\n",
            "Epoch 1/50\n",
            "1440/1440 [==============================] - 17s 12ms/step - loss: 0.1229 - accuracy: 0.1708 - val_loss: 0.1223 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.12235, saving model to top_model.h5\n",
            "Epoch 2/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.1206 - accuracy: 0.2069 - val_loss: 0.1223 - val_accuracy: 0.2042\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.12235 to 0.12232, saving model to top_model.h5\n",
            "Epoch 3/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.1181 - accuracy: 0.2604 - val_loss: 0.1222 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.12232 to 0.12224, saving model to top_model.h5\n",
            "Epoch 4/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.1117 - accuracy: 0.3438 - val_loss: 0.1221 - val_accuracy: 0.1521\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.12224 to 0.12214, saving model to top_model.h5\n",
            "Epoch 5/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0986 - accuracy: 0.4278 - val_loss: 0.1221 - val_accuracy: 0.1792\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.12214 to 0.12209, saving model to top_model.h5\n",
            "Epoch 6/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0812 - accuracy: 0.5458 - val_loss: 0.1217 - val_accuracy: 0.2625\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.12209 to 0.12166, saving model to top_model.h5\n",
            "Epoch 7/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0659 - accuracy: 0.6361 - val_loss: 0.1214 - val_accuracy: 0.2521\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.12166 to 0.12136, saving model to top_model.h5\n",
            "Epoch 8/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0548 - accuracy: 0.6924 - val_loss: 0.1249 - val_accuracy: 0.1937\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.12136\n",
            "Epoch 9/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0479 - accuracy: 0.7458 - val_loss: 0.1205 - val_accuracy: 0.1833\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.12136 to 0.12050, saving model to top_model.h5\n",
            "Epoch 10/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0379 - accuracy: 0.8042 - val_loss: 0.1227 - val_accuracy: 0.1667\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.12050\n",
            "Epoch 11/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0327 - accuracy: 0.8361 - val_loss: 0.1212 - val_accuracy: 0.2354\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.12050\n",
            "Epoch 12/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0245 - accuracy: 0.8903 - val_loss: 0.1268 - val_accuracy: 0.1979\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.12050\n",
            "Epoch 13/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0303 - accuracy: 0.8569 - val_loss: 0.1195 - val_accuracy: 0.2083\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.12050 to 0.11950, saving model to top_model.h5\n",
            "Epoch 14/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0163 - accuracy: 0.9271 - val_loss: 0.1362 - val_accuracy: 0.1937\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.11950\n",
            "Epoch 15/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0117 - accuracy: 0.9465 - val_loss: 0.1663 - val_accuracy: 0.2750\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.11950\n",
            "Epoch 16/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0103 - accuracy: 0.9576 - val_loss: 0.1319 - val_accuracy: 0.2146\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.11950\n",
            "Epoch 17/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0077 - accuracy: 0.9653 - val_loss: 0.1200 - val_accuracy: 0.2396\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.11950\n",
            "Epoch 18/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 0.9764 - val_loss: 0.1120 - val_accuracy: 0.3667\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.11950 to 0.11200, saving model to top_model.h5\n",
            "Epoch 19/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0050 - accuracy: 0.9806 - val_loss: 0.0930 - val_accuracy: 0.4708\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.11200 to 0.09303, saving model to top_model.h5\n",
            "Epoch 20/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0058 - accuracy: 0.9750 - val_loss: 0.1226 - val_accuracy: 0.2229\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.09303\n",
            "Epoch 21/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0076 - accuracy: 0.9708 - val_loss: 0.1630 - val_accuracy: 0.2833\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.09303\n",
            "Epoch 22/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0049 - accuracy: 0.9799 - val_loss: 0.1318 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.09303\n",
            "Epoch 23/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0042 - accuracy: 0.9799 - val_loss: 0.1033 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.09303\n",
            "Epoch 24/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0033 - accuracy: 0.9868 - val_loss: 0.0733 - val_accuracy: 0.5979\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.09303 to 0.07326, saving model to top_model.h5\n",
            "Epoch 25/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0024 - accuracy: 0.9910 - val_loss: 0.0513 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.07326 to 0.05132, saving model to top_model.h5\n",
            "Epoch 26/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0027 - accuracy: 0.9889 - val_loss: 0.0404 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.05132 to 0.04044, saving model to top_model.h5\n",
            "Epoch 27/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0020 - accuracy: 0.9924 - val_loss: 0.0471 - val_accuracy: 0.7812\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.04044\n",
            "Epoch 28/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0032 - accuracy: 0.9875 - val_loss: 0.0415 - val_accuracy: 0.8521\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.04044\n",
            "Epoch 29/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0014 - accuracy: 0.9944 - val_loss: 0.0488 - val_accuracy: 0.7771\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.04044\n",
            "Epoch 30/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0025 - accuracy: 0.9896 - val_loss: 0.0293 - val_accuracy: 0.9208\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.04044 to 0.02935, saving model to top_model.h5\n",
            "Epoch 31/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0026 - accuracy: 0.9896 - val_loss: 0.0515 - val_accuracy: 0.7708\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.02935\n",
            "Epoch 32/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 0.9847 - val_loss: 0.0468 - val_accuracy: 0.7521\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.02935\n",
            "Epoch 33/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9924 - val_loss: 0.0547 - val_accuracy: 0.7125\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.02935\n",
            "Epoch 34/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9903 - val_loss: 0.0287 - val_accuracy: 0.8708\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.02935 to 0.02874, saving model to top_model.h5\n",
            "Epoch 35/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0016 - accuracy: 0.9937 - val_loss: 0.0227 - val_accuracy: 0.9146\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.02874 to 0.02268, saving model to top_model.h5\n",
            "Epoch 36/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0020 - accuracy: 0.9917 - val_loss: 0.0152 - val_accuracy: 0.9583\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.02268 to 0.01525, saving model to top_model.h5\n",
            "Epoch 37/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0017 - accuracy: 0.9931 - val_loss: 0.0106 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.01525 to 0.01061, saving model to top_model.h5\n",
            "Epoch 38/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0015 - accuracy: 0.9931 - val_loss: 0.0152 - val_accuracy: 0.9646\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.01061\n",
            "Epoch 39/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9958 - val_loss: 0.0097 - val_accuracy: 0.9625\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.01061 to 0.00973, saving model to top_model.h5\n",
            "Epoch 40/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0011 - accuracy: 0.9958 - val_loss: 0.0105 - val_accuracy: 0.9521\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00973\n",
            "Epoch 41/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9958 - val_loss: 0.0085 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00973 to 0.00850, saving model to top_model.h5\n",
            "Epoch 42/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 9.7512e-04 - accuracy: 0.9965 - val_loss: 0.0069 - val_accuracy: 0.9625\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00850 to 0.00694, saving model to top_model.h5\n",
            "Epoch 43/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0011 - accuracy: 0.9944 - val_loss: 0.0066 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00694 to 0.00663, saving model to top_model.h5\n",
            "Epoch 44/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0018 - accuracy: 0.9924 - val_loss: 0.0092 - val_accuracy: 0.9563\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00663\n",
            "Epoch 45/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0022 - accuracy: 0.9910 - val_loss: 0.0077 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00663\n",
            "Epoch 46/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9937 - val_loss: 0.0058 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00663 to 0.00582, saving model to top_model.h5\n",
            "Epoch 47/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0017 - accuracy: 0.9924 - val_loss: 0.0065 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00582\n",
            "Epoch 48/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0013 - accuracy: 0.9951 - val_loss: 0.0058 - val_accuracy: 0.9771\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.00582 to 0.00581, saving model to top_model.h5\n",
            "Epoch 49/50\n",
            "1440/1440 [==============================] - 4s 2ms/step - loss: 0.0012 - accuracy: 0.9951 - val_loss: 0.0110 - val_accuracy: 0.9458\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00581\n",
            "Epoch 50/50\n",
            "1440/1440 [==============================] - 3s 2ms/step - loss: 9.0524e-04 - accuracy: 0.9965 - val_loss: 0.0058 - val_accuracy: 0.9688\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00581 to 0.00580, saving model to top_model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1ff851cd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9GukJpkpzsX",
        "colab_type": "code",
        "outputId": "8e778d69-a156-4b96-cc8c-4c0894b74437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "score = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.0057983114167655\n",
            "Test accuracy: 0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvqxNJEnp1hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('top_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-TjT3N70PR4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLTjtvmJv7uh",
        "colab_type": "code",
        "outputId": "c6605c33-5c36-469c-c399-ee3c1f2b8b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "score = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.0057983114167655\n",
            "Test accuracy: 0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM-QswOewLsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path=\"/content/1 (1).png\"\n",
        "pil_im =PIL.Image.open(img_path).convert('L')\n",
        "pil_im=blur_image(pil_im)\n",
        "org_img = img_to_array(pil_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY-3K2WywOV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rev_conv_label(label):\n",
        "    if label == 0 :\n",
        "        return 'adorsolipi'\n",
        "    elif label == 1:\n",
        "        return 'kalpurush'\n",
        "    elif label == 2 :\n",
        "        return 'lohit'\n",
        "    elif label == 3 :\n",
        "        return 'nikosh'\n",
        "    elif label == 4 :\n",
        "        return 'rupali'\n",
        "    elif label == 5 :\n",
        "        return 'solaimanlipi'\n",
        "    elif label == 6 :\n",
        "        return 'sonar_bangla'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8-SV5bY0wZCf",
        "colab": {}
      },
      "source": [
        "data=[]\n",
        "data.append(org_img)\n",
        "data = np.asarray(data, dtype=\"float\") / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqMaqxh0wcdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model.predict_classes(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFJXD6c2wcYO",
        "colab_type": "code",
        "outputId": "e45d4fbe-1036-4fa7-ceab-b3d9cc2c1573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "label = rev_conv_label(int(y[0]))\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(pil_im, interpolation='nearest', cmap=cm.gray)\n",
        "ax.text(5, 5, label , bbox={'facecolor': 'white', 'pad': 10})\n",
        "plt.show()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjqBASxR2Blq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}